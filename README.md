ğŸ“‚ **Multi-Source RAG System (Multimodal Retrieval-Augmented Generation)**

This project is a full-fledged **Multimodal Retrieval-Augmented Generation (RAG) system** that can respond to user queries by leveraging multiple data sources such as **CSVs, PDFs, scanned images, and Wikipedia articles**. By combining advanced **data ingestion, preprocessing, semantic search, and large language model inference**, the system delivers accurate, context-rich answers for real-world business applications.

---

ğŸš€ **Features**

* ğŸ“‘ **Multi-source ingestion**: CSVs, PDFs, scanned images, and Wikipedia articles
* ğŸ” **OCR processing**: Extract text from scanned documents using **EasyOCR**
* ğŸ§¹ **Tabular preprocessing**: Clean and convert structured CSV data for retrieval
* ğŸ“„ **PDF parsing**: Utilize **PyMuPDF** for accurate text extraction
* ğŸŒ **Knowledge expansion**: Incorporate related Wikipedia topics for richer context
* âœ‚ï¸ **Chunking & standardization**: Segment all text into manageable, uniform chunks
* ğŸ§  **Vector embeddings**: Encode with `all-MiniLM-L6-v2` for semantic similarity
* âš¡ **Efficient retrieval**: FAISS-based vector search with cosine similarity
* ğŸ¤– **LLM-powered responses**: Context-rich answers generated by **Mistral-7B-Instruct**
* ğŸ“Š **Evaluation**: Semantic similarity scoring with `multilingual-e5-base`
* âœ… **High accuracy**: Achieved cosine similarity of **91%**

---

ğŸ§  **Technologies Used**

* Python 3.8+
* EasyOCR
* PyMuPDF
* pandas
* FAISS
* Hugging Face Sentence Transformers (`all-MiniLM-L6-v2`, `multilingual-e5-base`)
* Mistral-7B-Instruct LLM

---

â–¶ï¸ **How to Run Locally**

1. **Clone the Repository**

```bash
git clone https://github.com/your-username/multimodal-rag.git
cd multimodal-rag
```

2. **Create a Virtual Environment**

```bash
python -m venv venv
source venv/bin/activate         # On Windows: venv\Scripts\activate
```

3. **Install Dependencies**

```bash
pip install -r requirements.txt
```

4. **Download Models**

```bash
python -m spacy download en_core_web_sm
# Download Hugging Face sentence transformer models as needed
```

5. **Run the Application**

```bash
python app.py
```

---

ğŸ“ **Example Use Case**

A data analyst uploads:

* a **customer churn CSV**,
* a **PDF report**,
* a set of **scanned contracts**,
* and a **Wikipedia topic** related to churn analysis.

The system ingests, processes, and indexes this multimodal data. When asked *â€œWhat factors contribute most to customer churn?â€*, the system retrieves the most relevant chunks across all data sources, builds a context-rich prompt, and generates a **well-formed, evidence-based response** with 91% semantic similarity accuracy.
